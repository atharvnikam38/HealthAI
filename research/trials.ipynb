{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6802d375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HealthAI\n"
     ]
    }
   ],
   "source": [
    "print(\"HealthAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35d26b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\all code\\\\HealthAI\\\\research'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb95829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7577d87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\all code\\\\HealthAI'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc9665ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0fc01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_file(data):\n",
    "    loader= DirectoryLoader(data,\n",
    "                            glob=\"*.pdf\",\n",
    "                            loader_cls=PyPDFLoader)\n",
    "\n",
    "    documents=loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13a9cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data=load_pdf_file(data='Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98b02101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfb85142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Data into Text Chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "794d24f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Chunks 5859\n"
     ]
    }
   ],
   "source": [
    "text_chunks=text_split(extracted_data)\n",
    "print(\"Length of Text Chunks\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2e5ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "219f6545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the Embeddings from Hugging Face\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9118592a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\athar\\AppData\\Local\\Temp\\ipykernel_4856\\2661704553.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f056e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Result [-0.10725167393684387, -0.003786760615184903, -0.10261969268321991, -0.01843501627445221, -0.029305515810847282, 0.07583676278591156, 0.09355117380619049, 0.06332724541425705, 0.018670517951250076, 0.01906520314514637, 0.059814561158418655, -0.032626353204250336, -0.0032167413737624884, 0.028507718816399574, -0.05649159103631973, 0.003930897917598486, -0.0242023766040802, 0.0336155965924263, 0.004469343926757574, 0.02434619329869747, -0.07919636368751526, 0.06492691487073898, 0.07414364814758301, -0.002374075585976243, 0.08786845207214355, -0.0005573790404014289, 0.012902187183499336, 0.03410455584526062, 0.012177342548966408, -0.08726773411035538, 0.1470288634300232, 0.013810628093779087, 0.04695095866918564, 0.013864259235560894, 0.04640413448214531, 0.06740625947713852, -0.1084694117307663, 0.06309249997138977, -0.04522407799959183, -0.0212301816791296, -0.01237428653985262, -0.029032191261649132, -0.005889868829399347, -0.023312369361519814, 0.01417246088385582, 0.07151288539171219, -0.0289143119007349, 0.07046923786401749, 0.07458348572254181, 0.001810578629374504, -0.07412441819906235, -0.04183761030435562, -0.032093364745378494, -0.009271116927266121, -0.005511575844138861, -0.05354325845837593, -0.05258861556649208, -0.04272453859448433, -0.062185000628232956, -0.05303119122982025, -0.06921172887086868, -0.027467915788292885, -0.03357662260532379, 0.011828103102743626, -0.015543975867331028, -0.022099951282143593, 0.05601884797215462, 0.0351073294878006, 0.0005016517825424671, 0.05485527217388153, 0.03239046037197113, -0.01554066315293312, -0.0422435961663723, 0.03967408835887909, -0.04108552262187004, -0.060604751110076904, 0.00469775777310133, -0.010188750922679901, 0.07228662818670273, -0.02872638963162899, -0.0030545047484338284, -0.09762373566627502, -0.046948131173849106, 0.0409964844584465, 0.0257777888327837, -0.04544006288051605, -0.022266004234552383, -0.01743309758603573, 0.02721201628446579, 0.038183700293302536, -0.03138734772801399, 0.009557674638926983, -0.027002129703760147, -0.05049991235136986, -0.017895488068461418, 0.05028222128748894, 0.04166332259774208, -0.006961627397686243, -0.013365602120757103, 0.12107516825199127, 0.02749592438340187, -0.03536401316523552, -0.12961532175540924, 0.00834862794727087, 0.036649029701948166, -0.016411297023296356, 0.055372145026922226, -0.0767497792840004, 0.018332356587052345, -0.006027044728398323, -0.03641324117779732, 0.0028204726986587048, -0.05473090708255768, -0.06142526865005493, 0.005346113815903664, 0.06915398687124252, 0.0033676682505756617, -0.04998185485601425, 0.007006222847849131, -0.04543585330247879, -0.07770387083292007, 0.006427125073969364, -0.05935893580317497, 0.07402671128511429, -0.023486429825425148, -0.03363902494311333, 0.00641509098932147, -4.897548439197285e-34, -0.01722852513194084, -0.12481231242418289, 0.008295594714581966, 0.04113622009754181, 0.002165936166420579, -0.015609819442033768, 0.06109063699841499, -0.04223988577723503, -0.07689572870731354, -0.10078232735395432, -0.06311755627393723, -0.0584932379424572, -0.09059988707304001, 0.0543724000453949, 0.10655321180820465, 0.009602447040379047, -0.0006223782547749579, -0.02350597456097603, -0.02308155782520771, -0.01693331077694893, -0.036133524030447006, 0.043621551245450974, 0.05704056844115257, 0.06752518564462662, 0.09139160066843033, -0.02406354807317257, 0.04512564837932587, -0.004322804510593414, -0.011418193578720093, 0.08676329255104065, 0.035613738000392914, 0.006626552902162075, -0.13622985780239105, -0.03127189353108406, -0.03980071470141411, -0.0019444371573626995, -0.1013890877366066, 0.01137818768620491, -0.0816778689622879, 0.0014807034749537706, 0.05811337009072304, 0.05021054670214653, -0.07340887188911438, 0.0033253261353820562, -0.020139843225479126, 0.03781428933143616, 0.03068840131163597, 0.02371475286781788, 0.005737603176385164, 0.06396112591028214, -0.007156368810683489, -0.038088083267211914, -0.046105578541755676, -0.016557607799768448, -0.05033465847373009, -0.004457124508917332, 0.018806109204888344, 0.017222005873918533, 0.012126623652875423, -0.012076735496520996, 0.012170764617621899, 0.020140523090958595, -0.028622997924685478, 0.0030071467626839876, -0.015508867800235748, -0.05845220386981964, 0.033603232353925705, 0.005528499837964773, -0.03905262425541878, -0.0205363892018795, -0.04628152400255203, -0.01229945570230484, 0.01693759113550186, 0.019414326176047325, -0.05411461740732193, 0.060607656836509705, -0.016144854947924614, -0.03581763058900833, 0.004751134663820267, 0.007780350279062986, -0.08565836399793625, 0.1170518770813942, 0.015992527827620506, 0.07180225104093552, -0.02834768407046795, -0.04716254398226738, 0.04326147586107254, -0.08485183864831924, -0.0710681676864624, 0.06379620730876923, -0.012912524864077568, 0.021357906982302666, 0.03610512986779213, -0.04528123885393143, -0.05578729137778282, -6.564376010611768e-34, -0.06172811985015869, 0.04471638798713684, -0.08259452134370804, 0.11609658598899841, -0.021456480026245117, 0.009704617783427238, 0.01137983612716198, 0.0920988991856575, -0.016347771510481834, 0.02492961846292019, -0.03233011066913605, -0.06722981482744217, -0.013821301981806755, 0.005403530318289995, 0.03922080248594284, 0.018727146089076996, 0.10018035769462585, 0.07368558645248413, -0.04058770462870598, 0.012904792092740536, 0.05039049685001373, 0.0666034072637558, 0.08867818117141724, -0.03626388683915138, -0.05905098468065262, 0.04102825000882149, 0.051203083246946335, 0.020439427345991135, -0.08626435697078705, 0.028919663280248642, 0.031798895448446274, -0.053256191313266754, -0.04538853093981743, 0.05027452111244202, -0.02267967164516449, 0.029096854850649834, 0.10900043696165085, 0.029454637318849564, -0.0495121031999588, -0.005803155712783337, 0.11960854381322861, -0.01238195039331913, -0.017752738669514656, 0.04873044788837433, 0.011109350249171257, -0.06549207121133804, -0.059740886092185974, 0.05768698453903198, -0.025415102019906044, -0.05379278212785721, 0.014365375973284245, -0.03210596367716789, 0.1146870106458664, 0.04569355770945549, 0.045557938516139984, -0.05164257436990738, -0.0010140234371647239, -0.024416949599981308, 0.00026034098118543625, -0.0022903489880263805, 0.043670304119586945, 0.008958778344094753, -0.07164441049098969, -0.016507500782608986, 0.008524310775101185, 0.05315964296460152, -0.03128373622894287, -0.03673318028450012, -0.026982540264725685, -0.029624372720718384, 0.03274766728281975, -0.09518182277679443, -0.059444863349199295, -0.021071651950478554, -0.04331550747156143, -0.014909010380506516, 0.004340703133493662, 0.059307996183633804, 0.04045998305082321, -0.04773253574967384, 0.0006707374122925103, -0.007107317913323641, -0.06357789039611816, 0.04832812398672104, 0.025276213884353638, 0.022074051201343536, 0.09104526787996292, -0.043311938643455505, 0.03897543624043465, 0.02487396076321602, 0.031474992632865906, 0.08730630576610565, 0.016210444271564484, -0.002650983165949583, -0.012948347255587578, -1.5394572727700506e-08, -0.01739346794784069, -0.04427428916096687, 0.017780793830752373, 0.01658538356423378, 0.09505219012498856, -0.06496106833219528, -0.048556625843048096, -0.004899566527456045, -0.03801991790533066, 0.08737783133983612, 0.06989389657974243, 0.021223507821559906, 0.027403924614191055, 0.018995201215147972, 0.07002546638250351, -0.028673024848103523, -0.048764199018478394, 0.05230092257261276, -0.06636565923690796, -0.051787395030260086, -0.057861775159835815, 0.06840616464614868, -0.04566064849495888, -0.04491912201046944, -0.0005450915778055787, 0.024153606966137886, -0.0044945282861590385, 0.013696854934096336, 0.1375221461057663, -0.033688027411699295, 0.025376152247190475, 0.10791358351707458, -0.0033195095602422953, -0.011889727786183357, -0.056749243289232254, -0.04082545265555382, 0.011674047447741032, -0.02256072126328945, 0.041317377239465714, 0.05422510206699371, -0.023060912266373634, 0.01828685961663723, 0.10869019478559494, 0.01866517774760723, -0.03546920418739319, 0.10114672780036926, 0.027816032990813255, -0.06125260517001152, -0.03308701515197754, 0.0012673125602304935, -0.07754360139369965, 0.059377800673246384, 0.03206659108400345, 0.05819909647107124, -0.04501017928123474, 0.024443021044135094, 0.028179341927170753, -0.09498216956853867, -0.03536028414964676, -0.053022246807813644, 0.12626366317272186, -0.025183064863085747, -0.11910474300384521, 0.08338642120361328]\n",
      "Type of Query Result <class 'list'>\n",
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Atharv Nikam\")\n",
    "print(\"Query Result\", query_result)\n",
    "print(\"Type of Query Result\", type(query_result))\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa280cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "577c66e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=os.environ.get('PINECONE_API_KEY')\n",
    "HUGGINGFACE_API_KEY=os.environ.get('HUGGINGFACE_API_KEY')\n",
    "GROQ_API_KEY=os.environ.get('GROQ_API_KEY')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d7b0bf6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "str expected, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPINECONE_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m PINECONE_API_KEY\n\u001b[0;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHUGGINGFACE_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m HUGGINGFACE_API_KEY\n\u001b[1;32m----> 4\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGROQ_API_KEY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m GROQ_API_KEY\n",
      "File \u001b[1;32mc:\\Users\\athar\\.conda\\envs\\medibot\\lib\\os.py:685\u001b[0m, in \u001b[0;36m_Environ.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__setitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value):\n\u001b[0;32m    684\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodekey(key)\n\u001b[1;32m--> 685\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencodevalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    686\u001b[0m     putenv(key, value)\n\u001b[0;32m    687\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[key] \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[1;32mc:\\Users\\athar\\.conda\\envs\\medibot\\lib\\os.py:743\u001b[0m, in \u001b[0;36m_createenviron.<locals>.check_str\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_str\u001b[39m(value):\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 743\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr expected, not \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[1;31mTypeError\u001b[0m: str expected, not NoneType"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = HUGGINGFACE_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8834b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Pinecone as PineconeVectorStore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c27d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "pc = Pinecone(api_key=\"pcsk_4mjmKP_569DnLkDkt6pU8aK3jJfUQuruR8WPnEeFB2CzRERJu4SsjL1DyRy4bdqQvAnRCy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5901a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "index_name = \"medicalbot\"\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5876f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "687736bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x2d2a0065570>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd686cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='432cf371-9091-44fc-be98-bf4fb5aa3aa9', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 39.0, 'page_label': '40', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data\\\\Medical_book.pdf', 'total_pages': 637.0}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 226\\nAcne\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 26'),\n",
       " Document(id='c4014fb7-8916-42cd-afc8-294639f21487', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 38.0, 'page_label': '39', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data\\\\Medical_book.pdf', 'total_pages': 637.0}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 2 25\\nAcne\\nAcne vulgaris affecting a woman’s face. Acne is the general\\nname given to a skin disorder in which the sebaceous\\nglands become inflamed. (Photograph by Biophoto Associ-\\nates, Photo Researchers, Inc. Reproduced by permission.)\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 25'),\n",
       " Document(id='b63dadc9-c331-4370-960a-34802d5034da', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 37.0, 'page_label': '38', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': 'Data\\\\Medical_book.pdf', 'total_pages': 637.0}, page_content='Acidosis see Respiratory acidosis; Renal\\ntubular acidosis; Metabolic acidosis\\nAcne\\nDefinition\\nAcne is a common skin disease characterized by\\npimples on the face, chest, and back. It occurs when the\\npores of the skin become clogged with oil, dead skin\\ncells, and bacteria.\\nDescription\\nAcne vulgaris, the medical term for common acne, is\\nthe most common skin disease. It affects nearly 17 million\\npeople in the United States. While acne can arise at any')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\n",
    "retrieved_docs = retriever.invoke(\"What is Acne?\")\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "108778b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from typing import Optional, List, Mapping, Any\n",
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class GroqChatLLM(LLM):\n",
    "    api_key: str = Field(..., description=\"Groq API key\")\n",
    "    model: str = Field(\"meta-llama/llama-4-scout-17b-16e-instruct\", description=\"Model name\")\n",
    "    api_url: str = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "        }\n",
    "        data = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"max_tokens\": 500,\n",
    "            \"temperature\": 0.4,\n",
    "        }\n",
    "        response = requests.post(self.api_url, headers=headers, json=data)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return result[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        return {\"model\": self.model}\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"groq-chat\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ddc567a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\athar\\AppData\\Local\\Temp\\ipykernel_4856\\8256292.py:5: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(llm(\"Explain the importance of fast language models\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models have become increasingly important in recent years due to their widespread applications in natural language processing (NLP) and artificial intelligence (AI). Here are some reasons why fast language models are crucial:\n",
      "\n",
      "1. **Improved User Experience**: Fast language models enable faster response times, which is essential for applications like chatbots, virtual assistants, and language translation systems. A faster model response time leads to a better user experience, increased engagement, and higher satisfaction.\n",
      "2. **Scalability**: As the demand for NLP applications grows, the need for fast language models that can handle large volumes of requests increases. Fast models can process more requests in a given time, making them more scalable and suitable for large-scale deployments.\n",
      "3. **Real-time Applications**: Many NLP applications, such as speech recognition, sentiment analysis, and text classification, require real-time processing. Fast language models can process and respond to requests in real-time, enabling applications like voice assistants, live language translation, and instant sentiment analysis.\n",
      "4. **Cost-effectiveness**: Faster language models require less computational resources, which translates to lower costs. By reducing the computational requirements, fast language models make it possible to deploy NLP applications on lower-cost hardware or in cloud environments, leading to cost savings.\n",
      "5. **Increased Productivity**: Fast language models can process and analyze large amounts of text data quickly, enabling researchers, developers, and analysts to focus on higher-level tasks like model interpretation, feature engineering, and decision-making.\n",
      "6. **Competitive Advantage**: In many industries, the speed and accuracy of NLP applications can be a key differentiator. Organizations that deploy fast and accurate language models can gain a competitive advantage over those that do not.\n",
      "7. **Edge AI**: With the proliferation of edge devices like smartphones, smart speakers, and IoT devices, there is a growing need for fast language models that can run on these devices. Fast language models enable edge AI applications like voice assistants, text analysis, and language translation on devices with limited computational resources.\n",
      "\n",
      "To achieve fast language models, researchers and developers have been exploring various techniques, such as:\n",
      "\n",
      "1. **Model pruning**: removing redundant or unnecessary weights and connections in the model.\n",
      "2. **Knowledge distillation**: transferring knowledge from a large model to a smaller one.\n",
      "3. **Efficient architectures**: designing models with efficient architectures, such as transformer-based models.\n",
      "4. **Quantization**: reducing the precision of model weights and activations.\n",
      "5. **Parallelization**: parallelizing model computations across multiple devices or cores.\n",
      "\n",
      "Some\n"
     ]
    }
   ],
   "source": [
    "api_key = \"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\"\n",
    "llm = GroqChatLLM(api_key=api_key)\n",
    "\n",
    "# Example: test your LLM\n",
    "print(llm(\"Explain the importance of fast language models\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b2706b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1f5e6afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8f1f4c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To treat acne, use topical drugs such as tretinoin, benzoyl peroxide, adapalene, or salicylic acid to reduce new comedones formation, and add topical antibiotics if inflammation is present. For mild cases, giving dry pimples limited sun exposure and maintaining a well-balanced diet while avoiding trigger foods may also help. Additionally, keep your hair clean, off your face, and avoid picking or squeezing blemishes.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"How to treat acne?\"})\n",
    "print(response[\"answer\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
